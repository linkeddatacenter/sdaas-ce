# Copyright (C) 2019-2020 LinkedData.Center - All Rights Reserved
# Permission to copy and modify is granted under the MIT license
if [ ! -z ${__module_bg_reasoning+x} ]; then return ; else __module_bg_reasoning=1 ; fi

SD_INCLUDE curl_utils

SD_REQUIRES_CMD mktemp dirname gzip cut tail


_SD_LOCAL_REASONER_STARTED=${_SD_LOCAL_REASONER_STARTED:-0}

##
# @description  creates an instance of blazegraph in http://localhost:8080/sdaas/sparql
#
# @arg $1 the memory footprints (default micro)
#
##
function SD_START_LOCAL_REASONING_ENGINE {
	local memoryFootprint="${1:-micro}"
	
	if [ $_SD_LOCAL_REASONER_STARTED -eq 1 ]; then
		SD_DEBUG_INFO "SD_START_LOCAL_REASONING_ENGINE already stared"
	else 
		/sdaas-start --size $memoryFootprint  > "$SD_CACHE/rdfstore.log" 2>&1 &
		if [ $? -eq 0 ]; then
			_SD_LOCAL_REASONER_STARTED=1
			SD_WARMUP_REASONING_ENGINE
		else
			SD_FATAL_ERROR "Error launcing local reasoner"
		fi
	fi
	SD_LOG "$memoryFootprint SPARQL endpoint available at http://localhost:8080/sdaas/sparql (logs in $SD_CACHE/rdfstore.log)"
}


##
# @description test that the engine is running
##
function SD_WARMUP_REASONING_ENGINE {
	local endpoint="${1:-"http://localhost:8080/sdaas"}"
	if [ $_SD_LOCAL_REASONER_STARTED -eq 1 ]; then
		local retry=1
		while ! curl -s -f -I "$endpoint/status"  > /dev/null ; do
			SD_LOG "Reasoning engine warming up $retry"
			sleep $(($retry*2))
			let retry++
			[ $retry -le 5 ] || SD_FATAL_ERROR "Sorry... internal reasoner startup failed.."
		done 
	fi
}



##
# @description  creates a reasoner based on blazegraph
##
function SD_STOP_LOCAL_REASONING_ENGINE {
	SD_DEBUG_INFO "$(/sdaas-stop)"
	_SD_LOCAL_REASONER_STARTED=0
}


##
# @description create a reasoner based on blazegraph extensions
# each reasoner can have an archetype (ie. specific features pre-configured). e.g.:
#  . **rdfs** implements an rdfs triplestore reasoner with both textual and geospatial features installed
#  . **geo** is a sparql quadstore  with [geospatial search](https://github.com/blazegraph/database/wiki/GeoSpatial)
#  . **lexical** is a sparql quadstore  with  lucene  [textual indices](https://github.com/blazegraph/database/wiki/FullTextSearch) to triplestore
#  . **smart** is a quadstore with both textual and geospatial features installed
# the namespace a **kb** is reserved
# knowledge base archetipes are in the scripts/archetipes directory
#
# @arg $1 a reasoner archetype
# @arg $2 a blazegraph endpoint
# @arg $3 namespace suffix (optional for testing purpose)
#
# @return the sparql service endpoint fot reasoner 
##
function SD_CREATE_REASONER {
	SD_REQUIRES_VAR 1
	local archetype="$1"
	local endpoint=${2:-"http://localhost:8080/sdaas"}
	local namespace="${3:-"$1-$RANDOM"}"
	
	[ "$namespace" != "kb" ] || SD_FATAL_ERROR "SD_CREATE_REASONER kb namespace is reserved"

	SD_DEBUG_INFO "In SD_CREATE_REASONER archetype=$archetype namespace=$namespace"
	
	local archetypes="$_SDAAS_DIR/archetypes"
		
	[ -f  "${archetypes}/${archetype}.txt" ] || SD_FATAL_ERROR "Invalid reasoner archetype $archetype."

	local description=$(cat "$archetypes/${archetype}.txt" | sed "s/%namespace/$namespace/g")
	
	local outputBuffer=$(SD_MK_DEBUG_TMP_FILE new_namespace)
	_SD_CURL_CMD \
		"$endpoint/namespace" \
		"$outputBuffer" \
		-X POST \
		--data-binary "$description" \
		--header 'Content-Type:text/plain' \
	|| SD_FATAL_ERROR "SD_CREATE_REASONER error creating namespace, see $outputBuffer"	
	SD_DEBUG_INFO "See create namespace output in $outputBuffer"
	if [ $SD_DEBUG -eq 0 ] ; then  rm -f "$outputBuffer" ; fi
	
	## Load specific archetype resources
	if [ -r "${archetypes}/${archetype}.ttl" ] ; then
		SD_REASONER_LOAD $namespace "${archetypes}/${archetype}.ttl" turtle "urn:sdaas:archetype:${archetype}"
	fi
	echo "$endpoint/namespace/$namespace/sparql"
}


##
# @description destroy a previpus created endpoint
#
# @arg $1 a blazegraph namespace sparql endpoint
##
function SD_DESTROY_REASONER {
	SD_REQUIRES_VAR 1
	local sparqlEndpoint="$1"
		
	SD_DEBUG_INFO "In SD_DESTROY_REASONER ${endpoint}"
	
	[[ $sparqlEndpoint =~ namespace/.+/sparql ]] || SD_FATAL_ERROR "SD_DESTROY_REASONER unable to destroy $endpoint"
	
	## Ignore errors in deleting a reasoner	
	endpoint=$(dirname "$sparqlEndpoint")
	SD_DEBUG_INFO "$(_SD_CURL_CMD "$endpoint" - -X DELETE)"
}


##
# @description a sparql query client output goes to stdout
#
# @example
#   SD_REASONER_QUERY rdfs text/csv "select * where {?s ?p ?o} LIMIT 1"
#   SD_REASONER_QUERY rdfs text/csv "@path/to/input_file_with_query"
#
# @arg $1 a sparql endpoint
# @arg $2 mime type for accepted result (i.e. text/csv or text/turtle) or some shortcuts:
#      "csv" a shortcut for text/csv
#      "csv-h" text/csv without  headers
# 	   "csv-1" return just first line (removing headers) in csv
# 	   "csv-f1" return just first field in first line (removing headers) in csv
#	   "bool" return true or false if result contains <value>true</value>
#	   "xml" a shortcut for application/sparql-results+xml
# @arg $3 a string with a valid sparql query statement (with extension) or a filename prefixed by the  @ character
#
# @exitcode 0  If successfull.
# @exitcode >0 On failure
##
function SD_REASONER_QUERY {
	local endpoint="$1"
	local request="$2"
	local query="$3"
	
	SD_DEBUG_INFO "In SD_REASONER_QUERY with endpoint=$endpoint request='$request' query='${query:0:40}'"

	local accept
	case "$request" in
		csv*) accept="text/csv" ; ;;
		bool|xml) accept="application/sparql-results+xml" ; ;;
		*) accept="$request" ; ;;
	esac
	
	local outputBuffer=$(SD_MK_DEBUG_TMP_FILE sparql_query_output)
	_SD_CURL_CMD \
		"${endpoint}" \
		"$outputBuffer" \
		-X POST \
		--data-binary "$query" \
		--header "Content-Type: application/sparql-query" \
		--header "Accept: $accept" \
	|| SD_FATAL_ERROR "SD_REASONER_QUERY failed, see $outputBuffer"	
	SD_DEBUG_INFO "See unfiltered output in $outputBuffer"
	
	# Post processing
	case "$request" in
		csv-h) tail -n +2 "$outputBuffer"; ;;
		csv-1) head -2 "$outputBuffer" | tail -1; ;;
		csv-f1) head -2 "$outputBuffer" | tail -1 | cut --delimiter=',' -f1; ;;
		bool) if grep -q "<boolean>true</boolean>" "$outputBuffer" ; then echo true;  else echo false; fi; ;;
		*) cat "$outputBuffer" ; ;;
	esac
	
	if [ $SD_DEBUG -eq 0 ] ; then  rm -f "$outputBuffer" ; fi
}


#
# @description a sparql update client output goes to stdout
#
# @arg $1 a sparql endpoint
# @arg $2 a sparql update string or @filename
#
function SD_REASONER_UPDATE {
	local endpoint="$1"
	local data="$2"
		
	SD_DEBUG_INFO  "In SD_REASONER_UPDATE with endpoint=$endpoint data='${data:0:40}'"

	local output=$(SD_MK_DEBUG_TMP_FILE SD_REASONER_UPDATE_output)	
	_SD_CURL_CMD \
		"${endpoint}" \
		"$output" \
		-X POST \
		--data-binary "$data" \
		--header "Content-Type: application/sparql-update" \
	|| SD_FATAL_ERROR "SD_REASONER_UPDATE failed: see $output"
	
	if [ $SD_DEBUG -eq 0 ]; then  rm -f "$output"; fi
}



##
# @description Simple loading of a a file into a reasoner. An shared upload directory must exist
#
# @arg $1 a sparql endpoint
# @arg $2 a graph name if "default" file is added to default graph
# @arg $3 an input file
# @arg $4 the input file format  Format can be: guess(default), 'turtle', 'ntriples', 'rdfxml'
# @ard $5 the upload directory (that must be referred 
##
function SD_REASONER_LOAD {
	local endpoint="$1"
	local graphName="$2"
	local inputFile="$3"
	local format="${4:-guess}"
	local uploadDir="${5:-/tmp/upload}"

	local extension
	case $format in
		turtle)   extension='ttl'; ;;
		ntriples) extension='nt'; ;;
		rdfxml)   extension='rdf'; ;;
		*)        extension="${inputFile##*.}"; ;;
	esac
	
	mkdir -p "$uploadDir" || SD_FATAL_ERROR "SD_LOAD_RDF_FILE failed creating upload dir in $uploadDir"	
	
	local sharedFile="$(mktemp --tmpdir="$uploadDir" "r-XXXXXXXXXX.$extension.gz")"
	gzip -c "$inputFile" > "$sharedFile"
	chmod +r "$sharedFile"
	
	if [ "$graphName" = "default" ]; then
		local graphStatement=""
	else
		local graphStatement=" INTO GRAPH <$graphName>"
	fi

    SD_REASONER_UPDATE "$endpoint" "LOAD <file://${sharedFile}>${graphStatement}"
	if [ $SD_DEBUG -lt 10 ]; then  rm -f "$sharedFile" ; fi	  
}


